# Параллельный парсинг веб-страниц с сохранением в базу данных

???+ question "Задание"

    Напишите программу на Python для параллельного парсинга нескольких веб-страниц с сохранением данных в базу данных 
    с использованием подходов threading, multiprocessing и async.  
    Каждая программа должна парсить информацию с нескольких веб-сайтов, сохранять их в базу данных.

Для начала создадим модуль для подключения к БД:

```Python title="db.py"
--8<-- "lr2/task2/db.py"
```

В качестве БД будем использовать PostgreSQL. Данные для подключения будем брать из виртуального окружения с помощью 
библиотеку `python-dotenv`.

Для подключения и работы с БД будем использовать `sqlalchemy` и `psycopg`.

Инициализируем сразу два `engine` и `sessionmaker`: синхронные и асинхронные, вторые будем использовать в реализации 
с помощью `asyncio`.

Создадим модель таблицы, в которой будем хранить спаршенные заголовки страниц:

=== "models.py"

    ```Python
    --8<-- "lr2/task2/models.py"
    ```

=== "enums.py"

    ```Python
    --8<-- "lr2/task2/enums.py"
    ```

Теперь приступим к написанию парсеров. В каждом из них в качестве HTTP клиента будем использовать клиент 
из библиотеки `httpx`, так как у него как синхронная, так и асинхронная реализация: так сравнение будет корректнее.

При сохранении в БД пометим используемый парсер в записи в Enum поле `parse_method`.

=== "threading"

    ```Python
    --8<-- "lr2/task2/parsers/threading_parser.py"
    ```

=== "multiprocessing"

    ```Python
    --8<-- "lr2/task2/parsers/multiprocessing_parser.py"
    ```

=== "asyncio"

    ```Python
    --8<-- "lr2/task2/parsers/asyncio_parser.py"
    ```

### Сравнение

| Подход          | Время выполнения    |
|-----------------|---------------------|
| threading       | 0.661628007888794   |
| multiprocessing | 0.4901440143585205  |
| asyncio         | 0.23399806022644043 |


Текущая задача больше I/O-bound (ожидание при подключении к БД, отправка запроса на сервер, ожидание ответа от сервера, 
отправка данных в БД), и поэтому вполне ожидаемо, что asyncio справится лучше всего.  
Но парсинг всего лишь заголовков и всего лишь нескольких сайтов – снова не очень корректная для сравнения задача.

Взглянем на время создания записей в БД:

| id | parse_method    | url                                                      | title                                              | created_at                 |
|----|-----------------|----------------------------------------------------------|----------------------------------------------------|----------------------------|
| 1  | THREADING       | https://student.itmo.ru/ru/expulsion_student_initiative/ | Отчисления по инициативе студента - ITMO.STUDENTS  | 2024-04-13 21:45:24.535542 |
| 2  | THREADING       | https://student.itmo.ru/ru/repeat_interim_exams/         | Повторная промежуточная аттестация - ITMO.STUDENTS | 2024-04-13 21:45:24.535723 |
| 3  | THREADING       | https://student.itmo.ru/ru/transfer/                     | Переводы - ITMO.STUDENTS                           | 2024-04-13 21:45:24.535951 |
| 6  | MULTIPROCESSING | https://student.itmo.ru/ru/transfer/                     | Переводы - ITMO.STUDENTS                           | 2024-04-13 21:46:00.997542 |
| 4  | MULTIPROCESSING | https://student.itmo.ru/ru/repeat_interim_exams/         | Повторная промежуточная аттестация - ITMO.STUDENTS | 2024-04-13 21:46:00.997543 |
| 5  | MULTIPROCESSING | https://student.itmo.ru/ru/expulsion_student_initiative/ | Отчисления по инициативе студента - ITMO.STUDENTS  | 2024-04-13 21:46:00.997694 |
| 7  | ASYNCIO         | https://student.itmo.ru/ru/transfer/                     | Переводы - ITMO.STUDENTS                           | 2024-04-13 21:46:09.634463 |
| 9  | ASYNCIO         | https://student.itmo.ru/ru/expulsion_student_initiative/ | Отчисления по инициативе студента - ITMO.STUDENTS  | 2024-04-13 21:46:09.634718 |
| 8  | ASYNCIO         | https://student.itmo.ru/ru/repeat_interim_exams/         | Повторная промежуточная аттестация - ITMO.STUDENTS | 2024-04-13 21:46:09.634889 |

Среднее время создания записи при использовании threading – примерно 0.2 мс.  
При использовании multiprocessing – примерно 0.15 мс.  
При использовании asyncio – примерно 0.2 мс.

То есть можно предположить, что при парсинге больших данных на гораздо большем количестве сайтов multiprocessing всё-таки 
выиграет, и это тоже в целом ожидаемо.