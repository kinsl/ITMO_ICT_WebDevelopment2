# Работа с фоновыми задачами в FastAPI

Бывает такое, что возникает необходимость при обращении к API вернуть ответ пользователю сразу, не дожидаясь выполнения 
какого-либо действия. Особенно это важно, когда это действие выполняется длительное время.

Примеры ситуаций, когда необходимо подобное поведение: 

- **Отправка email**: зачем пользователю дожидаться отправки, которая может занимать несколько секунд, чтобы ему потом просто 
сказали "Всё супер, можешь делать что-то дальше"?
- **Обработка большого количества данных**, например, генерация и скачивание CSV, ожидание которых может заблокировать 
пользователя более, чем на полчаса.

Для решения этих проблем существуют фоновые задачи, которые можно запустить как с помощью встроенного в FastAPI механизма 
`BackgroundTasks`, так и с более комплексного решения Celery.

Перед тем, как попробовать эти решения, попробуем симулировать проблему, чтобы лучше понять, зачем это действительно нужно.

Реализуем довольно базовую функцию, имитирующую отправку email, и эндпоинт, через который эта функция будет вызываться:

```Python
from fastapi import FastAPI

--8<-- "background_tasks/app.py:13:13"


--8<-- "background_tasks/app.py:16:19"


--8<-- "background_tasks/app.py:43:46"
```

Вместо фактического отправления email, будем записывать в файл `logs.log` дату и время "отправки", указанный почтовый адрес 
и случайный текст письма.  
В эндпоинте просто вызовем эту функцию, а после вернём JSON с сообщением об успехе.

Эта функция сейчас работает довольно быстро, и если мы обратимся к этому эндпоинту, практически мгновенно получим наш JSON. 
В данном случае никакой надобности в фоновых задачах нет.

Но фактическая отправка писем не работает так же тривиально, ведь нужно подключиться к почтовому серверу, подготовить чуть более 
сложный шаблон письма и провести ещё какие-либо необходимые операции.

Чтобы не усложнять примеры, просто добавим `sleep()` в нашу функцию:

```Python
--8<-- "background_tasks/app.py:22:26"


--8<-- "background_tasks/app.py:49:52"
```

Теперь, если мы обратимся к новому эндпоинту, ответ сервера мы получим примерно через 5 секунд. Неприятно.

Теперь попробуем вызвать эту же функцию с помощью упомянутого ранее `BackgroundTasks`. 

Для этого нам нужно указать в нашем эндпоинте параметр с объявленным типом `BackgroundTasks` (который мы импортируем напрямую из `fastapi`), 
а затем в эндпоинте вызвать у него метод `.add_task`, в который передадим нужную функцию и её аргументы (как позиционные, так и именованные):

```Python
from fastapi import BackgroundTasks


--8<-- "background_tasks/app.py:22:26"


--8<-- "background_tasks/app.py:55:58"
```

Сначала эндпоинт добавит задачу в "очередь", затем вернёт ответ пользователю и только потом запустит нашу задачу в фоне.

Соответственно, после получения ответа наше "письмо" появится в файле `logs.log` только через 5 секунд, и мы можем это проверить, 
если сравним время ответа сервера и время, которое сохранилось в файле.

Но что если пользователю нужно получить результат выполнения "тяжёлой" функции, но не хочется блокировать его в длительном ожидании 
(к тому же, в некоторых ситуациях это может быть чревато ошибкой Request Timeout)? Например, если, опять же, пользователю 
нужно сгенерировать большой CSV файл и скачать его?

В таком случае с `BackgroundTasks` не будет всё так просто, но можно попробовать выдумать костыли:

```Python
--8<-- "background_tasks/app.py:36:40"


--8<-- "background_tasks/app.py:67:86"
```

Здесь мы реализовали одну функцию и целых три эндпоинта:

Функция `write_csv` принимает в качестве аргумента название будущего условного CSV файла, засыпает на 20 секунд, имитируя 
генерацию файла, а потом создаёт файл с указанным названием и текущими датой и временем в качестве условного содержимого.

Эндпоинт `/csv/create` генерирует UUID в качестве случайного названия файла, создаёт фоновую задачу для генерации файла, а 
затем возвращает сгенерированное название файла.

В эндпоинт `/csv/check/{csv_name}` будем передавать полученное название файла, а в ответ сервер скажет, существует ли этот 
файл (статус `SUCCESS`) или нет (статус `PENDING`). Так мы можем условно проверить, выполнилась ли наша задача.

Эндпоинт `/csv/get/{csv_name}` будет возвращать содержимого файла с указанным названием.

Таким образом, если мы представим воображаемый фронтенд, через который пользователь хочет сгенерировать и получить CSV, его 
алгоритм будет следующий:

- Фронтенд обратится к эндпоинту для создания CSV и получит название файла;
- Фронтенд с помощью long polling будет обращаться к эндпоинту проверки наличия файла, пока не получит статус успеха;
- Фронтенд вернёт пользователю содержимое готового файла;
- Довольный пользователь получит файл, не подозревая о существовании наших костылей.

Звучит в целом неплохо, но только в нашей симулированной ситуации. На самом деле существует ряд проблем:

- Если данных очень много, генерация файла может тратить много ресурсов, и это будут ресурсы непосредственно нашего сервера, 
который параллельно должен обрабатывать запросы и других пользователей. В итоге серверу может быть тяжело и грустно, и 
другие пользователи будут дольше получать свои ответы;
- Существование файла на самом деле не говорит о том, что наша задача была выполнена. С таким подходом пользователь может 
получить лишь часть необходимых данных.
- Если вдруг во время генерации файла произошла ошибка, узнать об этом тоже нелегко. Опять же, пользователь может получить 
лишь часть данных или вовсе их не получить.

Решить перечисленные проблемы с помощью `BackgroundTasks` звучит очень сложной проблемой, если вообще возможной.

И именно в таких случаях нам может помочь Celery, распределённая очередь задач, которая запускается в отдельном процессе 
и удобно сообщает статусы и результаты наших задач.

Но чтобы использовать Celery, недостаточно просто импортировать какой-то класс и использовать его.

Нужно установить библиотеку, поднять брокер сообщений (который будет выступать очередью для наших задач) и результирующий 
бэкенд, который будет хранить результаты выполнения наших задач.

Собственно, в качестве брокера сообщений будем использовать RabbitMQ, а в качестве результирующего бэкенда – Redis.

Чтобы сильно не мучаться с их установкой и настройкой, просто поднимем их через Docker с помощью "коробочных" образов и все 
настройки оставим по умолчанию:

```yaml title="docker-compose.yml"
--8<-- "background_tasks/docker-compose.yml"
```

Теперь установим Celery:
```shell
pip install celery[redis]
```

И затем создадим новый модуль, в котором инициализируем приложение Celery и задачу, которую будем в дальнейшем вызывать: 

```Python title="celery_app.py"
--8<-- "background_tasks/celery_app.py"
```

Celery задачи помечаются с помощью декоратора `#!py3 @app.task`.

И мы сразу усложним нашу функцию, чтобы показать, какие ещё возможности открываются нам при использовании Celery: 
теперь наша функция не принимает название файла в качестве аргумента, а генерирует его сама, затем создаёт файл с этим названием 
и с тем же условным содержимым, а затем возвращает словарь с этим названием файла и с `user_id`, который задача получила 
в качестве аргумента.

Зачем передавать `user_id`? Представим, что у нашего сервиса настроенная авторизация, и мы бы не хотели, чтобы кто угодно 
мог скачивать чужие CSV файлы. Тогда пусть наша задача помимо названия файла возвращает и id запросившего генерацию пользователя! 
Потом, при попытке получить содержимое, будем сверять эти данные и блокировать доступ в случае чего.

Запустим Celery с помощью следующей команды:
```shell
python -m celery -A celery_app worker
```

Теперь нам нужно создать эндпоинты, чтобы вызывать нашу задачу и получать её результат:
```Python
from celery import current_app as celery_app

from celery_app import celery_write_csv


--8<-- "background_tasks/app.py:89:116"
```

Здесь мы импортировали прокси `current_app`, который укажет на используемое нами приложение Celery, и непосредственно нашу 
задачу, которую будем вызывать.

Новые эндпоинты очень схожи с теми, которые мы реализовали до этого.

Так как авторизация у нас не настроена, в качестве временной меры будем получать id пользователя через параметры.

В эндпоинте для создания CSV вызовем метод `.delay()` нашей задачи и передадим туда наш `user_id`. Вызов метода вернёт нам 
задачу, но из ценной информации там пока только её id. Его и вернём пользователю.

Результат задачи мы можем получить только если её статус – `SUCCESS`. Поэтому нам нужен эндпоинт для проверки этого статуса.

В эндпоинте проверки с помощью `#!py3 celery_app.AsyncResult(task_id)` вновь получим объект нашей задачи по её id. 
Если задача выполнилась, мы можем получить указанный для её создания `user_id` и сверить с тем, какой был передан для 
проверки её выполнения. При несовпадении заменим статус на `PROTECTED`. В любом ином случае просто вернём статус, какой он есть. 

В эндпоинте для получения CSV файла вновь проверим совпадение `user_id` и выбросим ошибку "Forbidden", если id не совпали.
Если id совпали, вернём содержимое файла с хранимым в задаче названием.

Алгоритм работы нашего воображаемого фронтенда почти не изменится:

- Фронтенд обратится к эндпоинту для создания CSV и получит id задачи;
- Фронтенд с помощью long polling будет обращаться к эндпоинту проверки статуса задачи, пока будет получать статус `PENDING`. 
Как только он получит статус `SUCCESS`, он перейдёт к следующему шагу. При получении любого другого статуса выбросит ошибку;
- Фронтенд вернёт пользователю содержимое готового файла, если id пользователя совпал;
- Довольный пользователь получит файл.

В полноценном сервисе, помимо реальной генерации CSV файла и использования рабочей авторизации, можно так же сохранять файл 
в стороннем хранилище и хранить в задаче не название файла, а ссылку на него.

И что ещё прекрасно, пользователь никаким образом не увидит, какой результат на самом деле хранится в нашей задаче, ведь 
мы не возвращаем его пользователю, а работаем с ним внутри эндпоинта. То есть при нужде мы можем добавить любую необходимую 
именно для нашего удобства информацию.